{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "anaconda-cloud": {},
    "colab": {
      "name": "Copy of main_train_corr_despecknet_cplx.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nPEY4wbfN6YH"
      },
      "source": [
        "**CV-DESPECKNET**\n",
        "\n",
        "**Version**: v1.2 \\\\\n",
        "**Date**: 2021-01-12 \\\\\n",
        "**Author**: Mullissa A.G. \\\\\n",
        "**Description**: This script trains a complex-valued multistream fully convolutional network for despeckling a polarimetric SAR covariance matrix as discussed in our paper A. G. Mullissa, C. Persello and J. Reiche, \"Despeckling Polarimetric SAR Data Using a Multistream Complex-Valued Fully Convolutional Network,\" in IEEE Geoscience and Remote Sensing Letters, doi: 10.1109/LGRS.2021.3066311. Some utility functions are adopted from https://github.com/cszn/DnCNN\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DRVu12-4aFMw"
      },
      "source": [
        "**SETTING UP THE ENVIORNMENT**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SNab3sAtMNgw",
        "outputId": "96ad2226-3f13-41ee-c1df-70c0b48fcc5f"
      },
      "source": [
        "#mount drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-SdJIBqCEkrS",
        "outputId": "f75c294c-d281-4bf6-82fa-6995a1939e32"
      },
      "source": [
        "#check GPU\n",
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
        "  print('and then re-execute this cell.')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sun Mar 28 15:44:02 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.56       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   39C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g5APznoIvIqp"
      },
      "source": [
        "#add path\n",
        "import sys\n",
        "sys.path.append('/content/drive/My Drive')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UFe2OSJBvMHA",
        "outputId": "eeeaa8fc-0f7e-4969-b10b-e991f15b34bf"
      },
      "source": [
        "#Install the right tensorflow and keras versions\n",
        "%tensorflow_version 1.x\n",
        "!pip uninstall keras\n",
        "!pip install keras==2.2.3"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n",
            "Uninstalling Keras-2.3.1:\n",
            "  Would remove:\n",
            "    /tensorflow-1.15.2/python3.7/Keras-2.3.1.dist-info/*\n",
            "    /tensorflow-1.15.2/python3.7/docs/*\n",
            "    /tensorflow-1.15.2/python3.7/keras/*\n",
            "Proceed (y/n)? y\n",
            "  Successfully uninstalled Keras-2.3.1\n",
            "Collecting keras==2.2.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/06/ea/ad52366ce566f7b54d36834f98868f743ea81a416b3665459a9728287728/Keras-2.2.3-py2.py3-none-any.whl (312kB)\n",
            "\u001b[K     |████████████████████████████████| 317kB 18.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras==2.2.3) (1.19.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras==2.2.3) (3.13)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras==2.2.3) (2.10.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from keras==2.2.3) (1.1.2)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from keras==2.2.3) (1.4.1)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /tensorflow-1.15.2/python3.7 (from keras==2.2.3) (1.0.8)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from keras==2.2.3) (1.15.0)\n",
            "Installing collected packages: keras\n",
            "  Found existing installation: Keras 2.4.3\n",
            "    Uninstalling Keras-2.4.3:\n",
            "      Successfully uninstalled Keras-2.4.3\n",
            "Successfully installed keras-2.2.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9DSpC6MOZ38P"
      },
      "source": [
        "**HELPERS**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9cKzIgBdMRJ3"
      },
      "source": [
        "import glob\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import tifffile\n",
        "\n",
        "patch_size, stride = 40, 9\n",
        "aug_times = 1\n",
        "scales = [1, 0.9, 0.8, 0.7]\n",
        "batch_size = 128\n",
        "\n",
        "def gen_patches(file_name):\n",
        "\n",
        "    # read image\n",
        "    img = tifffile.imread(file_name) \n",
        "    img = np.array(img)\n",
        "    h, w, d = img.shape\n",
        "    patches = []\n",
        "    for s in scales:\n",
        "        h_scaled, w_scaled = int(h*s),int(w*s)\n",
        "        img_scaled = cv2.resize(img, (h_scaled,w_scaled), interpolation=cv2.INTER_CUBIC)\n",
        "        # extract patches\n",
        "        for i in range(0, h_scaled-patch_size+1, stride):\n",
        "            for j in range(0, w_scaled-patch_size+1, stride):\n",
        "                x = img_scaled[i:i+patch_size, j:j+patch_size,:]\n",
        "                patches.append(x)        \n",
        "\n",
        "                \n",
        "    return patches\n",
        "\n",
        "def make_dataTensor(data_dir,verbose=False):\n",
        "    \n",
        "    file_list = glob.glob(data_dir+'/*.tif')  # get name list of all .tif files\n",
        "    # initrialize\n",
        "    data = []\n",
        "    # generate patches\n",
        "    for i in range(len(file_list)):\n",
        "        patch = gen_patches(file_list[i])\n",
        "        data.append(patch)\n",
        "        if verbose:\n",
        "            print(str(i+1)+'/'+ str(len(file_list)) + ' is done ^_^')\n",
        "    data = np.array(data)\n",
        "    data = data.reshape((data.shape[0]*data.shape[1],data.shape[2],data.shape[3],6))\n",
        "    discard_n = len(data)-len(data)//batch_size*batch_size;\n",
        "    data = np.delete(data,range(discard_n),axis = 0)\n",
        "    print(\"Finished generating data from {}\".format(data_dir))\n",
        "    return data\n",
        "\n",
        "def get_steps(data_dir, batch_size=128):\n",
        "    if os.path.isfile(data_dir):\n",
        "        noisy_files = [data_dir]\n",
        "    else:\n",
        "        noisy_files = glob.glob(data_dir + '/*.tif')\n",
        "    num = 0\n",
        "    #get number of steps per epoch to use in training\n",
        "    for data_file in noisy_files:\n",
        "        xs = make_dataTensor(data_dir)\n",
        "        if xs is not None: \n",
        "            num += len(xs)\n",
        "    print(\"total number of patches: {}\".format(num))\n",
        "    print(\"steps per epoch: {}\".format(num//batch_size))\n",
        "    print(\"\")\n",
        "    return num // batch_size"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tp-cgcPBabRJ"
      },
      "source": [
        "**DO THE JOB**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "6URbymYZ9lcj",
        "outputId": "8b06ad59-9876-440f-ba83-e5097af2a272"
      },
      "source": [
        "\n",
        "import complexnn\n",
        "import argparse\n",
        "import re\n",
        "import os, glob, datetime\n",
        "from keras.layers import  Input,Conv2D,BatchNormalization,Activation,Multiply, Add\n",
        "from keras.models import Model, load_model\n",
        "from keras.callbacks import CSVLogger, ModelCheckpoint, LearningRateScheduler\n",
        "from keras.optimizers import Adam\n",
        "import keras.backend as K\n",
        "\n",
        "\n",
        "save_dir = os.path.join('models','/content/drive/My Drive/modelCPLX_despecknet_SSE') \n",
        "\n",
        "if not os.path.exists(save_dir):\n",
        "    os.mkdir(save_dir)\n",
        "\n",
        "def cv_deSpeckNet(depth,filters=48,image_channels=6, use_bnorm=True):\n",
        "    layer_count = 0\n",
        "    inpt = Input(shape=(None,None,image_channels),name = 'input'+str(layer_count))\n",
        "    # 1st layer, CV-Conv+Crelu\n",
        "    layer_count += 1\n",
        "    x0 = complexnn.conv.ComplexConv2D(filters=filters, kernel_size=(3,3), strides=(1,1), activation='relu', padding='same',name = 'conv'+str(layer_count))(inpt)\n",
        "    # depth-2 layers, CV-Conv+CV-BN+Crelu\n",
        "    for i in range(depth-2):\n",
        "        layer_count += 1\n",
        "        x0 = complexnn.conv.ComplexConv2D(filters=filters, kernel_size=(3,3), strides=(1,1),activation='relu', padding='same',name = 'conv'+str(layer_count))(x0)\n",
        "        if use_bnorm:\n",
        "            layer_count += 1\n",
        "        x0 = complexnn.bn.ComplexBatchNormalization(name = 'bn'+str(layer_count))(x0)\n",
        "    # last layer, CV-Conv+Crelu\n",
        "    layer_count += 1\n",
        "    x0 = complexnn.conv.ComplexConv2D(filters=3, kernel_size=(3,3), strides=(1,1),padding='same',name = 'speckle'+str(1))(x0)\n",
        "    layer_count += 1\n",
        "    \n",
        "    # 1st layer, CV-Conv+Crelu\n",
        "    x = complexnn.conv.ComplexConv2D(filters=filters, kernel_size=(3,3), strides=(1,1), activation='relu', padding='same',name = 'conv'+str(layer_count))(inpt)\n",
        "    # depth-2 layers, CV-Conv+CV-BN+Crelu\n",
        "    for i in range(depth-2):\n",
        "        layer_count += 1\n",
        "        x = complexnn.conv.ComplexConv2D(filters=filters, kernel_size=(3,3), strides=(1,1),activation='relu', padding='same',name = 'conv'+str(layer_count))(x)\n",
        "        if use_bnorm:\n",
        "            layer_count += 1\n",
        "        x = complexnn.bn.ComplexBatchNormalization(name = 'bn'+str(layer_count))(x)\n",
        "    # last layer, CV-Conv\n",
        "    layer_count += 1\n",
        "    x = complexnn.conv.ComplexConv2D(filters=3, kernel_size=(3,3), strides=(1,1),padding='same',name = 'clean'+str(1))(x)\n",
        "    layer_count += 1\n",
        "    x_orig = Add(name = 'noisy' +  str(1))([x0,x])\n",
        "    \n",
        "    model = Model(inputs=inpt, outputs=[x,x_orig])\n",
        "    \n",
        "    return model\n",
        "\n",
        "\n",
        "def findLastCheckpoint(save_dir):\n",
        "    file_list = glob.glob(os.path.join(save_dir,'model_*.hdf5'))  # get name list of all .hdf5 files\n",
        "    #file_list = os.listdir(save_dir)\n",
        "    if file_list:\n",
        "        epochs_exist = []\n",
        "        for file_ in file_list:\n",
        "            result = re.findall(\".*model_(.*).hdf5.*\",file_)\n",
        "            #print(result[0])\n",
        "            epochs_exist.append(int(result[0]))\n",
        "        initial_epoch=max(epochs_exist)   \n",
        "    else:\n",
        "        initial_epoch = 0\n",
        "    return initial_epoch\n",
        "\n",
        "def log(args,kwargs):\n",
        "     print(datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S:\"),args,kwargs)\n",
        "\n",
        "def lr_schedule(epoch):\n",
        "    initial_lr = 1e-3\n",
        "    if epoch<=30:\n",
        "        lr = initial_lr\n",
        "    elif epoch<=60:\n",
        "        lr = initial_lr/10\n",
        "    elif epoch<=80:\n",
        "        lr = initial_lr/20 \n",
        "    else:\n",
        "        lr = initial_lr/20 \n",
        "    #log('current learning rate is %2.8f' %lr)\n",
        "    return lr\n",
        "\n",
        "def train_datagen(epoch_iter=2000,epoch_num=5,batch_size=64,data_dir='/content/drive/My Drive/data_cplx/New_train',label_dir='/content/drive/My Drive/data_cplx/New_label_final'):\n",
        "    while(True):\n",
        "        n_count = 0\n",
        "        if n_count == 0:\n",
        "            #print(n_count)\n",
        "            xs = make_dataTensor(data_dir)\n",
        "            xy = make_dataTensor(label_dir)\n",
        "            assert len(xs)%batch_size ==0, \\\n",
        "            log('make sure the last iteration has a full batchsize, this is important if you use batch normalization!')\n",
        "            xs = xs.astype('float32')\n",
        "            xy = xy.astype('float32')\n",
        "            indices = list(range(xs.shape[0]))\n",
        "            n_count = 1\n",
        "        for _ in range(epoch_num):\n",
        "            np.random.shuffle(indices)    # shuffle\n",
        "            for i in range(0, len(indices), batch_size):\n",
        "                batch_x = xs[indices[i:i+batch_size]]\n",
        "                batch_y = xy[indices[i:i+batch_size]]\n",
        "                yield batch_x, [batch_y, batch_x]\n",
        "        \n",
        "# sum square error loss function\n",
        "def sum_squared_error(y_true, y_pred):\n",
        "    return K.sum(K.square(y_pred - y_true))/2\n",
        "    \n",
        "if __name__ == '__main__':\n",
        "    # model selection\n",
        "    model = cv_deSpeckNet(depth=17,filters=48,image_channels=6,use_bnorm=True)\n",
        "    model.summary()\n",
        "    \n",
        "    # load the last model in matconvnet style\n",
        "    initial_epoch = findLastCheckpoint(save_dir=save_dir)\n",
        "    if initial_epoch > 0:  \n",
        "        print('resuming by loading epoch %03d'%initial_epoch)\n",
        "        model = load_model(os.path.join(save_dir,'model_%03d.hdf5'%initial_epoch), custom_objects={'ComplexConv2D': complexnn.conv.ComplexConv2D, 'ComplexBatchNormalization': complexnn.bn.ComplexBatchNormalization, 'sum_squared_error': sum_squared_error})\n",
        "\n",
        "    loss_funcs = {\n",
        "        'clean1': sum_squared_error,\n",
        "        'noisy1' : sum_squared_error}\n",
        "    \n",
        "    loss_weights = {'clean1': 100.0, 'noisy1': 1.0}\n",
        "    \n",
        "    # compile the model\n",
        "    model.compile(optimizer=Adam(0.001), loss=loss_funcs, loss_weights=loss_weights)\n",
        "    \n",
        "    # use call back functions\n",
        "    checkpointer = ModelCheckpoint(os.path.join(save_dir,'model_{epoch:03d}.hdf5'), \n",
        "                verbose=1, save_weights_only=False, period=1)\n",
        "    csv_logger = CSVLogger(os.path.join(save_dir,'log.csv'), append=True, separator=',')\n",
        "    lr_scheduler = LearningRateScheduler(lr_schedule)\n",
        "\n",
        "    nsteps = get_steps(data_dir='/content/drive/My Drive/data_cplx/New_train', batch_size=128)\n",
        "    \n",
        "    history = model.fit_generator(train_datagen(batch_size=64),\n",
        "                steps_per_epoch=nsteps, epochs=52, verbose=1, initial_epoch=initial_epoch,\n",
        "                callbacks=[checkpointer,csv_logger,lr_scheduler])\n",
        "\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/variables.py:2825: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:131: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input0 (InputLayer)             (None, None, None, 6 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv33 (ComplexConv2D)          (None, None, None, 9 2688        input0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv1 (ComplexConv2D)           (None, None, None, 9 2688        input0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv34 (ComplexConv2D)          (None, None, None, 9 41568       conv33[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2 (ComplexConv2D)           (None, None, None, 9 41568       conv1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "bn35 (ComplexBatchNormalization (None, None, None, 9 480         conv34[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "bn3 (ComplexBatchNormalization) (None, None, None, 9 480         conv2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv36 (ComplexConv2D)          (None, None, None, 9 41568       bn35[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "conv4 (ComplexConv2D)           (None, None, None, 9 41568       bn3[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "bn37 (ComplexBatchNormalization (None, None, None, 9 480         conv36[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "bn5 (ComplexBatchNormalization) (None, None, None, 9 480         conv4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv38 (ComplexConv2D)          (None, None, None, 9 41568       bn37[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "conv6 (ComplexConv2D)           (None, None, None, 9 41568       bn5[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "bn39 (ComplexBatchNormalization (None, None, None, 9 480         conv38[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "bn7 (ComplexBatchNormalization) (None, None, None, 9 480         conv6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv40 (ComplexConv2D)          (None, None, None, 9 41568       bn39[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "conv8 (ComplexConv2D)           (None, None, None, 9 41568       bn7[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "bn41 (ComplexBatchNormalization (None, None, None, 9 480         conv40[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "bn9 (ComplexBatchNormalization) (None, None, None, 9 480         conv8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv42 (ComplexConv2D)          (None, None, None, 9 41568       bn41[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "conv10 (ComplexConv2D)          (None, None, None, 9 41568       bn9[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "bn43 (ComplexBatchNormalization (None, None, None, 9 480         conv42[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "bn11 (ComplexBatchNormalization (None, None, None, 9 480         conv10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv44 (ComplexConv2D)          (None, None, None, 9 41568       bn43[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "conv12 (ComplexConv2D)          (None, None, None, 9 41568       bn11[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "bn45 (ComplexBatchNormalization (None, None, None, 9 480         conv44[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "bn13 (ComplexBatchNormalization (None, None, None, 9 480         conv12[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv46 (ComplexConv2D)          (None, None, None, 9 41568       bn45[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "conv14 (ComplexConv2D)          (None, None, None, 9 41568       bn13[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "bn47 (ComplexBatchNormalization (None, None, None, 9 480         conv46[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "bn15 (ComplexBatchNormalization (None, None, None, 9 480         conv14[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv48 (ComplexConv2D)          (None, None, None, 9 41568       bn47[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "conv16 (ComplexConv2D)          (None, None, None, 9 41568       bn15[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "bn49 (ComplexBatchNormalization (None, None, None, 9 480         conv48[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "bn17 (ComplexBatchNormalization (None, None, None, 9 480         conv16[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv50 (ComplexConv2D)          (None, None, None, 9 41568       bn49[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "conv18 (ComplexConv2D)          (None, None, None, 9 41568       bn17[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "bn51 (ComplexBatchNormalization (None, None, None, 9 480         conv50[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "bn19 (ComplexBatchNormalization (None, None, None, 9 480         conv18[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv52 (ComplexConv2D)          (None, None, None, 9 41568       bn51[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "conv20 (ComplexConv2D)          (None, None, None, 9 41568       bn19[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "bn53 (ComplexBatchNormalization (None, None, None, 9 480         conv52[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "bn21 (ComplexBatchNormalization (None, None, None, 9 480         conv20[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv54 (ComplexConv2D)          (None, None, None, 9 41568       bn53[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "conv22 (ComplexConv2D)          (None, None, None, 9 41568       bn21[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "bn55 (ComplexBatchNormalization (None, None, None, 9 480         conv54[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "bn23 (ComplexBatchNormalization (None, None, None, 9 480         conv22[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv56 (ComplexConv2D)          (None, None, None, 9 41568       bn55[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "conv24 (ComplexConv2D)          (None, None, None, 9 41568       bn23[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "bn57 (ComplexBatchNormalization (None, None, None, 9 480         conv56[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "bn25 (ComplexBatchNormalization (None, None, None, 9 480         conv24[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv58 (ComplexConv2D)          (None, None, None, 9 41568       bn57[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "conv26 (ComplexConv2D)          (None, None, None, 9 41568       bn25[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "bn59 (ComplexBatchNormalization (None, None, None, 9 480         conv58[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "bn27 (ComplexBatchNormalization (None, None, None, 9 480         conv26[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv60 (ComplexConv2D)          (None, None, None, 9 41568       bn59[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "conv28 (ComplexConv2D)          (None, None, None, 9 41568       bn27[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "bn61 (ComplexBatchNormalization (None, None, None, 9 480         conv60[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "bn29 (ComplexBatchNormalization (None, None, None, 9 480         conv28[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv62 (ComplexConv2D)          (None, None, None, 9 41568       bn61[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "conv30 (ComplexConv2D)          (None, None, None, 9 41568       bn29[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "bn63 (ComplexBatchNormalization (None, None, None, 9 480         conv62[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "bn31 (ComplexBatchNormalization (None, None, None, 9 480         conv30[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "clean1 (ComplexConv2D)          (None, None, None, 6 2598        bn63[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "speckle1 (ComplexConv2D)        (None, None, None, 6 2598        bn31[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "noisy1 (Add)                    (None, None, None, 6 0           speckle1[0][0]                   \n",
            "                                                                 clean1[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 1,272,012\n",
            "Trainable params: 1,264,812\n",
            "Non-trainable params: 7,200\n",
            "__________________________________________________________________________________________________\n",
            "resuming by loading epoch 051\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/utils/io_utils.py:186: H5pyDeprecationWarning: The default file mode will change to 'r' (read-only) in h5py 3.0. To suppress this warning, pass the mode you need to h5py.File(), or set the global default h5.get_config().default_file_mode, or set the environment variable H5PY_DEFAULT_READONLY=1. Available modes are: 'r', 'r+', 'w', 'w-'/'x', 'a'. See the docs for details.\n",
            "  self.data = h5py.File(path,)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:186: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Finished generating data from /content/drive/My Drive/data_cplx/New_train\n",
            "Finished generating data from /content/drive/My Drive/data_cplx/New_train\n",
            "total number of patches: 133376\n",
            "steps per epoch: 1042\n",
            "\n",
            "Epoch 52/52\n",
            "Finished generating data from /content/drive/My Drive/data_cplx/New_train\n",
            "Finished generating data from /content/drive/My Drive/data_cplx/New_label_final\n",
            " 226/1042 [=====>........................] - ETA: 18:29 - loss: 435660.3356 - clean1_loss: 4335.5028 - noisy1_loss: 2110.0556"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-8eba81aa3b51>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    137\u001b[0m     history = model.fit_generator(train_datagen(batch_size=64),\n\u001b[1;32m    138\u001b[0m                 \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnsteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m52\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m                 callbacks=[checkpointer,csv_logger,lr_scheduler])\n\u001b[0m\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    214\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[1;32m    215\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m                                             class_weight=class_weight)\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}
